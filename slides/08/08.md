title: NPFL139, Lecture 8
class: title, langtech, cc-by-sa
# PAAC, PPO

## Milan Straka

### April 08, 2024

---
section: PAAC
# Parallel Advantage Actor Critic

An alternative to independent workers is to train in a synchronous and
centralized way by having the workers to only generate episodes. Such approach
was described in 2017 as **parallel advantage actor-critic** (PAAC) by [Clemente
et al., https://arxiv.org/abs/1705.04862](https://arxiv.org/abs/1705.04862).

![w=70%,h=center](paac_framework.svgz)

---
# Parallel Advantage Actor Critic

![w=85%,h=center](paac_algorithm.svgz)

---
# Parallel Advantage Actor Critic

![w=70%,h=center](paac_performance.svgz)

The authors use $8$ workers, $n_e=32$ parallel environments, $5$-step returns,
$γ=0.99$, $ε=0.1$, $β=0.01$, and a learning rate of $α=0.0007⋅n_e=0.0224$.

The $\textrm{arch}_\textrm{nips}$ is from A3C: 16 filters $8×8$ stride 4, 32
filters $4×4$ stride 2, a dense layer with 256 units. The
$\textrm{arch}_\textrm{nature}$ is from DQN: 32 filters $8×8$ stride 4, 64
filters $4×4$ stride 2, 64 filters $3×3$ stride 1 and 512-unit fully connected
layer. All nonlinearities are ReLU.

---
# Parallel Advantage Actor Critic

![w=100%](paac_workers_epochs.svgz)

---
# Parallel Advantage Actor Critic

![w=100%](paac_workers_time.svgz)

---
# Parallel Advantage Actor Critic

![w=100%,v=middle](paac_time_usage.svgz)

